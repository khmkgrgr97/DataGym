{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hw3_train.csv', sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('use_savings',axis = 1)\n",
    "df = df.drop('use_guarantees',axis = 1)\n",
    "df = df.drop('use_derivada_account',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:-1]]\n",
    "y = df[\"use_direct_debit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('forest', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'forest__max_depth': range(2, 15),\n",
    "              'forest__n_estimators': range(50, 150),\n",
    "              'forest__max_features': range(1, 20),\n",
    "              'forest__min_samples_split': range(1,5),\n",
    "              'forest__min_samples_leaf': range(1, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10, total=   0.3s\n",
      "[CV] forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10, total=   0.3s\n",
      "[CV] forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10, total=   0.3s\n",
      "[CV] forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10, total=   0.3s\n",
      "[CV] forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=92, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=10, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=3, forest__max_depth=11, total=   0.3s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=18, forest__max_depth=2, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=2, forest__min_samples_leaf=1, forest__max_features=12, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8, total=   0.0s\n",
      "[CV] forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8, total=   0.0s\n",
      "[CV] forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8, total=   0.0s\n",
      "[CV] forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8, total=   0.0s\n",
      "[CV] forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=126, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=8, total=   0.0s\n",
      "[CV] forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14, total=   0.0s\n",
      "[CV] forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14, total=   0.0s\n",
      "[CV] forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14, total=   0.0s\n",
      "[CV] forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14, total=   0.0s\n",
      "[CV] forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=100, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=11, forest__max_depth=14, total=   0.0s\n",
      "[CV] forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8, total=   0.5s\n",
      "[CV] forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8, total=   0.5s\n",
      "[CV] forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8, total=   0.5s\n",
      "[CV] forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8, total=   0.5s\n",
      "[CV] forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=128, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=8, forest__max_depth=8, total=   0.5s\n",
      "[CV] forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6, total=   0.0s\n",
      "[CV] forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6, total=   0.0s\n",
      "[CV] forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6, total=   0.0s\n",
      "[CV] forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6, total=   0.0s\n",
      "[CV] forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=99, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=6, total=   0.0s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6, total=   0.2s\n",
      "[CV] forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=80, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=6, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=10, forest__max_depth=3, total=   0.2s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=63, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=82, forest__min_samples_split=1, forest__min_samples_leaf=1, forest__max_features=4, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10, total=   0.2s\n",
      "[CV] forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=53, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=10, total=   0.2s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=50, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=4, total=   0.0s\n",
      "[CV] forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7, total=   0.5s\n",
      "[CV] forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7, total=   0.5s\n",
      "[CV] forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7, total=   0.5s\n",
      "[CV] forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7, total=   0.5s\n",
      "[CV] forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=132, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=7, total=   0.5s\n",
      "[CV] forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8, total=   0.3s\n",
      "[CV] forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8, total=   0.3s\n",
      "[CV] forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8, total=   0.3s\n",
      "[CV] forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8, total=   0.3s\n",
      "[CV] forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8 \n",
      "[CV]  forest__n_estimators=69, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=9, forest__max_depth=8, total=   0.3s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9, total=   0.0s\n",
      "[CV] forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=107, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=9, total=   0.0s\n",
      "[CV] forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=112, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=4, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=10, forest__max_depth=9, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=6, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=13, total=   0.0s\n",
      "[CV] forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12, total=   0.0s\n",
      "[CV] forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12, total=   0.0s\n",
      "[CV] forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12, total=   0.0s\n",
      "[CV] forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12, total=   0.0s\n",
      "[CV] forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=101, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=12, total=   0.0s\n",
      "[CV] forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7 \n",
      "[CV]  forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=148, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=4, forest__max_depth=7, total=   0.1s\n",
      "[CV] forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10, total=   0.4s\n",
      "[CV] forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10, total=   0.4s\n",
      "[CV] forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10, total=   0.4s\n",
      "[CV] forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10, total=   0.4s\n",
      "[CV] forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=149, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=2, forest__max_depth=10, total=   0.4s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=1, forest__max_depth=9, total=   0.2s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=12, forest__max_depth=14, total=   0.8s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=19, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=98, forest__min_samples_split=3, forest__min_samples_leaf=1, forest__max_features=5, forest__max_depth=2, total=   0.2s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9, total=   0.3s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=119, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=4, forest__max_depth=9, total=   0.3s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11, total=   0.5s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11, total=   0.5s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11, total=   0.5s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11, total=   0.5s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=3, forest__min_samples_leaf=3, forest__max_features=8, forest__max_depth=11, total=   0.5s\n",
      "[CV] forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4, total=   0.5s\n",
      "[CV] forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4, total=   0.5s\n",
      "[CV] forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4, total=   0.5s\n",
      "[CV] forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4, total=   0.5s\n",
      "[CV] forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=129, forest__min_samples_split=3, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=4, total=   0.5s\n",
      "[CV] forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14, total=   0.4s\n",
      "[CV] forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14, total=   0.4s\n",
      "[CV] forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14, total=   0.4s\n",
      "[CV] forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14, total=   0.4s\n",
      "[CV] forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14 \n",
      "[CV]  forest__n_estimators=71, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=14, forest__max_depth=14, total=   0.4s\n",
      "[CV] forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10, total=   0.5s\n",
      "[CV] forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10, total=   0.5s\n",
      "[CV] forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10, total=   0.5s\n",
      "[CV] forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10, total=   0.5s\n",
      "[CV] forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=89, forest__min_samples_split=4, forest__min_samples_leaf=2, forest__max_features=15, forest__max_depth=10, total=   0.5s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=2, forest__max_features=14, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10, total=   0.8s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10, total=   0.8s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10, total=   0.8s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10, total=   0.7s\n",
      "[CV] forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=122, forest__min_samples_split=2, forest__min_samples_leaf=4, forest__max_features=17, forest__max_depth=10, total=   0.8s\n",
      "[CV] forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6 \n",
      "[CV]  forest__n_estimators=74, forest__min_samples_split=4, forest__min_samples_leaf=4, forest__max_features=8, forest__max_depth=6, total=   0.3s\n",
      "[CV] forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13, total=   0.8s\n",
      "[CV] forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13, total=   0.8s\n",
      "[CV] forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13, total=   0.8s\n",
      "[CV] forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13, total=   0.8s\n",
      "[CV] forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=143, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=14, forest__max_depth=13, total=   0.8s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10, total=   0.0s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10, total=   0.0s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10, total=   0.0s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10 \n",
      "[CV]  forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10, total=   0.0s\n",
      "[CV] forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=119, forest__min_samples_split=1, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=10, total=   0.0s\n",
      "[CV] forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=120, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=3, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4, total=   0.3s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4, total=   0.3s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4, total=   0.3s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4, total=   0.3s\n",
      "[CV] forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4 \n",
      "[CV]  forest__n_estimators=124, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=5, forest__max_depth=4, total=   0.3s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3 \n",
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=115, forest__min_samples_split=1, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=3, total=   0.0s\n",
      "[CV] forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13, total=   0.5s\n",
      "[CV] forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=102, forest__min_samples_split=3, forest__min_samples_leaf=2, forest__max_features=7, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2 \n",
      "[CV]  forest__n_estimators=105, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=13, forest__max_depth=2, total=   0.3s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11, total=   0.2s\n",
      "[CV] forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11 \n",
      "[CV]  forest__n_estimators=88, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=1, forest__max_depth=11, total=   0.2s\n",
      "[CV] forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=75, forest__min_samples_split=4, forest__min_samples_leaf=1, forest__max_features=16, forest__max_depth=5, total=   0.3s\n",
      "[CV] forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5 \n",
      "[CV]  forest__n_estimators=77, forest__min_samples_split=1, forest__min_samples_leaf=4, forest__max_features=18, forest__max_depth=5, total=   0.0s\n",
      "[CV] forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/jupyter/jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12, total=   0.5s\n",
      "[CV] forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12, total=   0.5s\n",
      "[CV] forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12, total=   0.5s\n",
      "[CV] forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12, total=   0.4s\n",
      "[CV] forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12 \n",
      "[CV]  forest__n_estimators=72, forest__min_samples_split=4, forest__min_samples_leaf=3, forest__max_features=16, forest__max_depth=12, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('forest',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     ccp_alpha=0.0,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features='auto',\n",
       "                                                                     max_leaf_nodes=Non...\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=1,\n",
       "                   param_distributions={'forest__max_depth': range(2, 15),\n",
       "                                        'forest__max_features': range(1, 20),\n",
       "                                        'forest__min_samples_leaf': range(1, 5),\n",
       "                                        'forest__min_samples_split': range(1, 5),\n",
       "                                        'forest__n_estimators': range(50, 150)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Запускаем поиск гиперпараметров\n",
    "hyper_search = RandomizedSearchCV(mypipeline, param_grid, n_iter=50, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=1, refit=True, random_state=123,\n",
    "                                  verbose=2)\n",
    "hyper_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forest__n_estimators': 122,\n",
       " 'forest__min_samples_split': 3,\n",
       " 'forest__min_samples_leaf': 3,\n",
       " 'forest__max_features': 8,\n",
       " 'forest__max_depth': 11}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197764101512963"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посредством поиска определили следующие лучшие гиперпараметры для случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_best = {'forest__max_depth': [13],\n",
    "              'forest__n_estimators': [106],\n",
    "              'forest__max_features': [5],\n",
    "              'forest__min_samples_split': [2],\n",
    "              'forest__min_samples_leaf': [3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13, total=   0.4s\n",
      "[CV] forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13 \n",
      "[CV]  forest__n_estimators=106, forest__min_samples_split=2, forest__min_samples_leaf=3, forest__max_features=5, forest__max_depth=13, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('forest',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     ccp_alpha=0.0,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features='auto',\n",
       "                                                                     max_leaf_nodes=Non...\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=1, n_jobs=1,\n",
       "                   param_distributions={'forest__max_depth': [13],\n",
       "                                        'forest__max_features': [5],\n",
       "                                        'forest__min_samples_leaf': [3],\n",
       "                                        'forest__min_samples_split': [2],\n",
       "                                        'forest__n_estimators': [106]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Запускаем поиск гиперпараметров\n",
    "hyper_search = RandomizedSearchCV(mypipeline, param_grid_best, n_iter=1, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=1, refit=True, random_state=123,\n",
    "                                  verbose=2)\n",
    "hyper_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9194562115128008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_forest = hyper_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим Bagging над RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bag', BaggingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = {'bag__base_estimator': [best_model_forest],\n",
    "               'bag__n_estimators': range(50,70,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.0s\n",
      "[CV] bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.3s\n",
      "[CV] bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.1s\n",
      "[CV] bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  18.3s\n",
      "[CV] bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=53, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  18.5s\n",
      "[CV] bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  20.6s\n",
      "[CV] bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  21.7s\n",
      "[CV] bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  20.6s\n",
      "[CV] bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  20.2s\n",
      "[CV] bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=59, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  21.0s\n",
      "[CV] bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  22.4s\n",
      "[CV] bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  22.3s\n",
      "[CV] bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  22.0s\n",
      "[CV] bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  22.5s\n",
      "[CV] bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=62, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  23.9s\n",
      "[CV] bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  17.8s\n",
      "[CV] bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  17.8s\n",
      "[CV] bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.3s\n",
      "[CV] bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  17.6s\n",
      "[CV] bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=50, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  17.8s\n",
      "[CV] bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  20.0s\n",
      "[CV] bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.8s\n",
      "[CV] bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.8s\n",
      "[CV] bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  19.7s\n",
      "[CV] bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False) \n",
      "[CV]  bag__n_estimators=56, bag__base_estimator=Pipeline(memory=None,\n",
      "         steps=[('scaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=13, max_features=5,\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=3, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=106, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False), total=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('bag',\n",
       "                                              BaggingClassifier(base_estimator=None,\n",
       "                                                                bootstrap=True,\n",
       "                                                                bootstrap_features=False,\n",
       "                                                                max_features=1.0,\n",
       "                                                                max_samples=1.0,\n",
       "                                                                n_estimators=10,\n",
       "                                                                n_jobs=None,\n",
       "                                                                oob_...\n",
       "                                                                                                        min_impurity_decrease=0.0,\n",
       "                                                                                                        min_impurity_split=None,\n",
       "                                                                                                        min_samples_leaf=3,\n",
       "                                                                                                        min_samples_split=2,\n",
       "                                                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                                                        n_estimators=106,\n",
       "                                                                                                        n_jobs=None,\n",
       "                                                                                                        oob_score=False,\n",
       "                                                                                                        random_state=None,\n",
       "                                                                                                        verbose=0,\n",
       "                                                                                                        warm_start=False))],\n",
       "                                                                         verbose=False)],\n",
       "                                        'bag__n_estimators': range(50, 70, 3)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Запускаем поиск гиперпараметров\n",
    "hyper_search2 = RandomizedSearchCV(mypipeline2, param_grid2, n_iter=5, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=1, refit=True, random_state=123,\n",
    "                                  verbose=2)\n",
    "hyper_search2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__n_estimators': 62, 'bag__base_estimator': Pipeline(memory=None,\n",
       "          steps=[('scaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('forest',\n",
       "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                         class_weight=None, criterion='gini',\n",
       "                                         max_depth=13, max_features=5,\n",
       "                                         max_leaf_nodes=None, max_samples=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=3, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=106, n_jobs=None,\n",
       "                                         oob_score=False, random_state=None,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919952683915269"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search2.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bagging = hyper_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('hw3_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('use_savings',axis = 1)\n",
    "df_test = df_test.drop('use_guarantees',axis = 1)\n",
    "df_test = df_test.drop('use_derivada_account',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_test = df_test[df_test.columns[1:]]\n",
    "y_hat = best_model_bagging.predict_proba(X_real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(zip(df_test['customer_id'], y_hat[:, 1]), \n",
    "            columns = ['customer_id', 'use_direct_debit']).to_csv('predictions_bagging8.csv',\n",
    "                                                                  sep=',',\n",
    "                                                                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
